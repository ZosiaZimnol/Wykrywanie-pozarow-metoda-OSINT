from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from app.routes import test
from app.routes.reddit_scraper import scrape_and_store_posts
from app.db.database import get_db_connection
from app.routes.nasa_scraper import fetch_and_store_nasa_fires
import threading
import time


app = FastAPI()

# Middleware CORS (dla frontendÃ³w lokalnych)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # MoÅ¼esz ograniczyÄ‡ do frontendu
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Rejestracja routerÃ³w
app.include_router(test.router)
print("âœ… ROUTER ZOSTAÅ ZAÅADOWANy")

@app.get("/")
async def root():
    return {"message": "API dziaÅ‚a poprawnie"}

@app.get("/ping")
async def ping():
    return {"message": "pong"}

@app.get("/ping-db")
async def ping_db():
    try:
        print("ğŸ”„ PrÃ³ba poÅ‚Ä…czenia z bazÄ… danych...")
        conn = get_db_connection()
        print("âœ… PoÅ‚Ä…czono z bazÄ….")
        cur = conn.cursor()
        cur.execute("SELECT * FROM lokalizacja LIMIT 1;")
        result = cur.fetchone()
        cur.close()
        conn.close()
        return {"db": "ok", "result": result}
    except Exception as e:
        print(f"âŒ BÅ‚Ä…d poÅ‚Ä…czenia z DB: {e}")
        return {"db": "error", "details": str(e)}

@app.get("/pozar-count")
def count_pozary():
    conn = get_db_connection()
    cur = conn.cursor()
    cur.execute("SELECT COUNT(*) FROM pozar;")
    count = cur.fetchone()[0]
    cur.close()
    conn.close()
    return {"count": count}

# Funkcja uruchamiajÄ…ca scraper okresowo
def periodic_scrape(interval_seconds=60):
    while True:
        print("ğŸ” Automatyczne pobieranie danych z Reddita i NASA...")
        try:
            scrape_and_store_posts()
            print("âœ… Dane z Reddita zostaÅ‚y zapisane.")
        except Exception as e:
            print(f"âŒ BÅ‚Ä…d scrapera Reddit: {e}")
        try:
            fetch_and_store_nasa_fires()
            print("âœ… Dane z NASA zostaÅ‚y zapisane.")
        except Exception as e:
            print(f"âŒ BÅ‚Ä…d scrapera NASA: {e}")
        time.sleep(interval_seconds)


@app.on_event("startup")
def start_background_scraper():
    threading.Thread(target=periodic_scrape, daemon=True).start()
