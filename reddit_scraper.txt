# app/routes/reddit_scraper.py
import praw
from datetime import datetime
from app.db.database import get_db_connection

reddit = praw.Reddit(
    client_id="TWOJE_CLIENT_ID",
    client_secret="TWOJE_CLIENT_SECRET",
    username="TWOJ_LOGIN",
    password="TWOJE_HASLO",
    user_agent="fire_osint_app"
)

SUBREDDITS = ["fire", "wildfire", "naturaldisasters"]

def scrape_and_store_posts():
    conn = get_db_connection()
    cur = conn.cursor()

    for sub in SUBREDDITS:
        for post in reddit.subreddit(sub).hot(limit=10):
            title = post.title
            content = post.selftext
            source = f"https://www.reddit.com{post.permalink}"
            created = datetime.utcfromtimestamp(post.created_utc).date()

            # ðŸ”¥ Zapisz jako "raport" i "pozar"
            cur.execute("""
                INSERT INTO pozar (data_wykrycia, opis, zrodlo_danych, wiarygodnosc)
                VALUES (%s, %s, %s, %s) RETURNING id_pozaru;
            """, (created, title, "Reddit", 0.85))
            pozar_id = cur.fetchone()[0]

            cur.execute("""
                INSERT INTO raport (tekst, data_publikacji, autor, pozar_id_pozaru)
                VALUES (%s, %s, %s, %s)
            """, (content[:3000], created, post.author.name, pozar_id))

    conn.commit()
    cur.close()
    conn.close()
